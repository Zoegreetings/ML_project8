# ML_project8
Built a LSTM based multi-headed model that’s capable of detecting different types of toxicity of a comment, like threats, obscenity, insults, and identity-based hate; trained the model with the dataset of comments from Wikipedia’s talk page edits; the model showed validation accuracy as high as 98%.
